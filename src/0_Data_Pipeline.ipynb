{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aKGCTbPM917",
    "outputId": "43c7af4a-6dba-4ad3-f8e2-13d128c71e95"
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.tsa.stattools import acf, adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.svm import SVR\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG2muxLYNZiP"
   },
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data downloaded from:\n",
    "\n",
    " - https://zenodo.org/record/5946808#.ZGNpddbP23I\n",
    " - https://zenodo.org/record/5841834#.ZGNpTNbP23J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fBXDHhbXNYrU"
   },
   "outputs": [],
   "source": [
    "# read in files\n",
    "turbine_status = pd.read_csv('../data/Windturbinen/Kelmarsh/Status_Kelmarsh_1_2016-01-03_-_2017-01-01_228.csv',\n",
    "                             skiprows = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "1JOJBOQmJ8vW",
    "outputId": "9ef7cb4d-1722-4065-d36c-5d6e1c78e881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp start', 'Timestamp end', 'Duration', 'Status', 'Code',\n",
      "       'Message', 'Comment', 'Service contract category', 'IEC category'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp start</th>\n",
       "      <th>Timestamp end</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Status</th>\n",
       "      <th>Code</th>\n",
       "      <th>Message</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Service contract category</th>\n",
       "      <th>IEC category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-14 19:28:03</td>\n",
       "      <td>2016-01-23 14:36:32</td>\n",
       "      <td>211:08:29</td>\n",
       "      <td>Stop</td>\n",
       "      <td>111</td>\n",
       "      <td>Emergency stop nacelle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emergency stop switch (Nacelle) (11)</td>\n",
       "      <td>Forced outage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-14 19:28:03</td>\n",
       "      <td>2016-01-14 19:38:03</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>Warning</td>\n",
       "      <td>5720</td>\n",
       "      <td>Brake accumulator defect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warnings (27)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-14 19:28:05</td>\n",
       "      <td>2016-01-23 11:27:46</td>\n",
       "      <td>207:59:41</td>\n",
       "      <td>Informational</td>\n",
       "      <td>3835</td>\n",
       "      <td>Cable panel breaker open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warnings (27)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-14 19:28:05</td>\n",
       "      <td>2016-01-23 11:27:46</td>\n",
       "      <td>207:59:41</td>\n",
       "      <td>Informational</td>\n",
       "      <td>3830</td>\n",
       "      <td>Supply circuit breaker earthed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warnings (27)</td>\n",
       "      <td>Full Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-14 19:28:05</td>\n",
       "      <td>2016-01-23 14:09:18</td>\n",
       "      <td>210:41:13</td>\n",
       "      <td>Warning</td>\n",
       "      <td>3870</td>\n",
       "      <td>Overload transformer fan outlet air</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warnings (27)</td>\n",
       "      <td>Full Performance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp start        Timestamp end   Duration         Status  Code  \\\n",
       "0  2016-01-14 19:28:03  2016-01-23 14:36:32  211:08:29           Stop   111   \n",
       "1  2016-01-14 19:28:03  2016-01-14 19:38:03   00:10:00        Warning  5720   \n",
       "2  2016-01-14 19:28:05  2016-01-23 11:27:46  207:59:41  Informational  3835   \n",
       "3  2016-01-14 19:28:05  2016-01-23 11:27:46  207:59:41  Informational  3830   \n",
       "4  2016-01-14 19:28:05  2016-01-23 14:09:18  210:41:13        Warning  3870   \n",
       "\n",
       "                               Message  Comment  \\\n",
       "0               Emergency stop nacelle      NaN   \n",
       "1             Brake accumulator defect      NaN   \n",
       "2             Cable panel breaker open      NaN   \n",
       "3       Supply circuit breaker earthed      NaN   \n",
       "4  Overload transformer fan outlet air      NaN   \n",
       "\n",
       "              Service contract category      IEC category  \n",
       "0  Emergency stop switch (Nacelle) (11)     Forced outage  \n",
       "1                         Warnings (27)               NaN  \n",
       "2                         Warnings (27)               NaN  \n",
       "3                         Warnings (27)  Full Performance  \n",
       "4                         Warnings (27)  Full Performance  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(turbine_status.columns)\n",
    "turbine_status.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status data is not relevant to this thesis !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turbine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_Windturbines (turbine_directory):\n",
    "    # Columns to keep\n",
    "    columns_to_keep = [\n",
    "        '# Date and time',\n",
    "        'Wind speed (m/s)',\n",
    "        'Long Term Wind (m/s)',\n",
    "        'Energy Export (kWh)'\n",
    "    ]\n",
    "\n",
    "    # Directory containing CSV files\n",
    "    directory = f'../data/Windturbinen/{turbine_directory}/'\n",
    "\n",
    "    # Dictionary to hold DataFrames for each turbine\n",
    "    turbine_dataframes = defaultdict(list)\n",
    "\n",
    "    # Get a list of CSV files in the directory\n",
    "    csv_files = [f for f in os.listdir(directory) if f.startswith(f\"Turbine_Data_{turbine_directory}_\") and f.endswith(\".csv\")]\n",
    "\n",
    "    # Iterate through the files in the directory with a tqdm progress bar\n",
    "    for filename in tqdm(csv_files, desc='Processing files'):\n",
    "        # Extract the turbine number from the filename\n",
    "        turbine_number = filename.split(\"_\")[3]  # Assuming the number is in this position\n",
    "\n",
    "        # Read the CSV file, skipping the first 9 rows\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath, skiprows=9, usecols=columns_to_keep)\n",
    "\n",
    "        # Convert the \"Date and time\" column to datetime\n",
    "        df['# Date and time'] = pd.to_datetime(df['# Date and time'])\n",
    "\n",
    "        # Append the DataFrame to the appropriate turbine's list\n",
    "        turbine_dataframes[turbine_number].append(df)\n",
    "\n",
    "    # Concatenate the DataFrames for each turbine\n",
    "    for turbine_number, dfs in turbine_dataframes.items():\n",
    "        turbine_dataframes[turbine_number] = pd.concat(dfs)\n",
    "        turbine_dataframes[turbine_number].sort_values('# Date and time', inplace=True)\n",
    "\n",
    "    # Print the keys for the dictionary\n",
    "    print(\"\\n dictionary keys:\")\n",
    "    print(turbine_dataframes.keys())\n",
    "    # print descriptive stuff for exemplary key\n",
    "    print('\\n Information for exemplary key:')\n",
    "    first_key = list(turbine_dataframes.keys())[0]\n",
    "    print('shape')\n",
    "    print(turbine_dataframes[first_key].shape)\n",
    "    print('\\n missing values')\n",
    "    print(turbine_dataframes[first_key].isna().sum())\n",
    "\n",
    "    return turbine_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 36/36 [00:18<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dictionary keys:\n",
      "dict_keys(['6', '4', '1', '3', '2', '5'])\n",
      "\n",
      " Information for exemplary key:\n",
      "shape\n",
      "(288864, 4)\n",
      "\n",
      " missing values\n",
      "# Date and time            0\n",
      "Wind speed (m/s)        9223\n",
      "Long Term Wind (m/s)       0\n",
      "Energy Export (kWh)     5072\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Kelmarsh_df = reading_Windturbines('Kelmarsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 84/84 [00:45<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dictionary keys:\n",
      "dict_keys(['07', '08', '02', '05', '06', '15', '10', '14', '01', '04', '11', '12', '13', '09'])\n",
      "\n",
      " Information for exemplary key:\n",
      "shape\n",
      "(267014, 4)\n",
      "\n",
      " missing values\n",
      "# Date and time            0\n",
      "Wind speed (m/s)        5881\n",
      "Long Term Wind (m/s)       0\n",
      "Energy Export (kWh)     1032\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Penmanshiel_df = reading_Windturbines('Penmanshiel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlexGuide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ENIT_2022_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# merge files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ENIT_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ENIT_2022_1, ENIT_2022_2, ENIT_2023_1])\n\u001b[1;32m      4\u001b[0m \u001b[39m# rename columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ENIT_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m ENIT_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mWirkarbeit (Bezug) \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mstrip()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ENIT_2022_1' is not defined"
     ]
    }
   ],
   "source": [
    "# merge files\n",
    "ENIT_df = pd.concat([ENIT_2022_1, ENIT_2022_2, ENIT_2023_1])\n",
    "\n",
    "# rename columns\n",
    "ENIT_df.columns = ENIT_df.columns.str.replace('Wirkarbeit (Bezug) ', '').str.strip()\n",
    "\n",
    "# add residual columns\n",
    "ENIT_df['1.8 - Residual'] = ENIT_df.iloc[:, 1] - ENIT_df.iloc[:, 2:8].sum(axis=1)\n",
    "ENIT_df['2.7 - Residual'] = ENIT_df.iloc[:, 9] - ENIT_df.iloc[:, 10:15].sum(axis=1)\n",
    "ENIT_df['0.1 - Residual'] = ENIT_df.iloc[:, 16] - ENIT_df.iloc[:, 1] - ENIT_df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in each column:\n",
      "1.0 - Trafo 1 [Wh]                                   0\n",
      "1.1 - Neubau, Wohnhaus, Holzplatz [Wh]               0\n",
      "1.2 - Halle 3/1 Absaugung [Wh]                       0\n",
      "1.3 - Halle 4/2 Maschinensaal/Tischfertigung [Wh]    0\n",
      "1.4 - Halle 2/2 Verwaltung, Entwicklung [Wh]         0\n",
      "1.5 - Halle 4/5 Lackieranlage [Wh]                   0\n",
      "1.6 - Halle 1/6 Hausmeister [Wh]                     0\n",
      "1.7 - Halle 3/3 Kompressor, Stuhlmontage [Wh]        0\n",
      "2.0 - Trafo 2 [Wh]                                   0\n",
      "2.1 - Halle 4/5 Schrankfertigung [Wh]                0\n",
      "2.2 - Halle 2/4 Rilsan [Wh]                          0\n",
      "2.3 - Halle 4/5 Stahlstuhl [Wh]                      0\n",
      "2.4 - Halle 4/1 Schichtholz [Wh]                     0\n",
      "2.5 - Halle 4/1 Absaugung Schichtholz [Wh]           0\n",
      "dtype: int64\n",
      "\n",
      "Indices of outliers:\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation for each column\n",
    "mean = ENIT_df.iloc[:, 1:15].mean()\n",
    "std_dev = ENIT_df.iloc[:, 1:15].std()\n",
    "\n",
    "# Identify outliers using twice the standard deviation\n",
    "outliers = (ENIT_df.iloc[:, 1:15] < (mean - 2 * std_dev)) | (ENIT_df.iloc[:, 1:15] > (mean + 2 * std_dev))\n",
    "\n",
    "# Print the number of True values in each column\n",
    "print(\"Number of outliers in each column:\")\n",
    "print(outliers.sum())\n",
    "\n",
    "# Get the row and column indices of the True values\n",
    "true_values_indices = outliers.where(outliers).stack().index\n",
    "\n",
    "# Print the row and column indices of the True values\n",
    "print(\"\\nIndices of outliers:\")\n",
    "for row, col in true_values_indices:\n",
    "    print(f\"Row: {row}, Column: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ENIT_df.shape)\n",
    "ENIT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.  , 20000.  , 40000.  , ..., 66666.67, 86666.67, 73333.33])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENIT_df['Übergabezähler [Wh]'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values\n",
    "print(ENIT_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data as dict with each company as a key\n",
    "FlexGuideData = {\n",
    "    'MechTron': ENIT_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PV-ZBfp_N0g9"
   },
   "source": [
    "# pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IOsKtDGGN3XK"
   },
   "outputs": [],
   "source": [
    "def outlier_detection(data, dependent_var, independent_var):\n",
    "    # only keep demand and one other variable\n",
    "    df = data[[f'{dependent_var}', f'{independent_var}']]\n",
    "\n",
    "    # check for outliers\n",
    "    # Calculate the mean and standard deviation for each column\n",
    "    mean = df.mean()\n",
    "    std_dev = df.std()\n",
    "\n",
    "    # Identify outliers using twice the standard deviation\n",
    "    outliers = (df < (mean - 3 * std_dev)) | (df > (mean + 3 * std_dev))\n",
    "\n",
    "    # Print the number of True values in each column\n",
    "    print(\"Number of outliers in each column:\")\n",
    "    print(outliers.sum())\n",
    "\n",
    "    # Get the row and column indices of the True values\n",
    "    true_values_indices = outliers.where(outliers).stack().index\n",
    "\n",
    "    # Print the row and column indices of the True values\n",
    "    print(\"\\nIndices of outliers:\")\n",
    "    for row, col in true_values_indices:\n",
    "        print(f\"Row: {row}, Column: {col}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l2Cx0G9nPnJw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in each column:\n",
      "Energy Export (kWh)     6\n",
      "Long Term Wind (m/s)    0\n",
      "dtype: int64\n",
      "\n",
      "Indices of outliers:\n",
      "Row: 27407, Column: Energy Export (kWh)\n",
      "Row: 10456, Column: Energy Export (kWh)\n",
      "Row: 17788, Column: Energy Export (kWh)\n",
      "Row: 24557, Column: Energy Export (kWh)\n",
      "Row: 26026, Column: Energy Export (kWh)\n",
      "Row: 37678, Column: Energy Export (kWh)\n"
     ]
    }
   ],
   "source": [
    "# column names as strings\n",
    "Kelmarsh_1 = outlier_detection(Kelmarsh_df['1'], 'Energy Export (kWh)', 'Long Term Wind (m/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'Kelmarsh_df' (defaultdict)\n",
      "Stored 'Penmanshiel_df' (defaultdict)\n"
     ]
    }
   ],
   "source": [
    "%store Kelmarsh_df Penmanshiel_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SV9yrwwoludt",
    "WFSxTQUYOACR",
    "bWY6Vk-AF6WJ",
    "13hFG5tvHieq",
    "-pYSYeXQHqQV"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
