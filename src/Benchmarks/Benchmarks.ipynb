{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Modules\n",
    "from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
    "from layers.SelfAttention_Family import ProbAttention, AttentionLayer, FullAttention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla Transformer with O(L^2) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(VanillaTransformer, self).__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(configs.d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def DecoderInput(data):\n",
    "        mid_point = tensor.size(1) // 2  # Calculate the midpoint\n",
    "        first_half_last_six = tensor[:, mid_point-6:mid_point, :]  # Select the last six values from the first half\n",
    "        second_half_last_six = tensor[:, -6:, :]  # Select the last six values from the second half\n",
    "        concatenated_tensor = torch.cat((first_half_last_six, second_half_last_six), dim=1)\n",
    "        \n",
    "        return concatenated_tensor\n",
    "\n",
    "    def forward(self, input_data,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "        enc_in = input_data\n",
    "        enc_out, attns = self.encoder(enc_in, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_in = DecoderInput(enc_in)\n",
    "        dec_out = self.decoder(dec_in, enc_in, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], attns\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Informer with Propspare attention in O(LlogL) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, configs, input_data):\n",
    "        super(Model, self).__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.input_data = input_data\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            [\n",
    "                ConvLayer(\n",
    "                    configs.d_model\n",
    "                ) for l in range(configs.e_layers - 1)\n",
    "            ] if configs.distil else None,\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(configs.d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "        enc_in = input_data\n",
    "        enc_out, attns = self.encoder(enc_in, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_in = DecoderInput(enc_in)\n",
    "        dec_out = self.decoder(dec_in, enc_in, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], attns\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape: torch.Size([512, 144, 64])\n"
     ]
    }
   ],
   "source": [
    "%store -r embeddings hyperparameters\n",
    "print(f\"feature shape: {embeddings.shape}\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "hyperparameters = Config(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VanillaTransformer(hyperparameters, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
