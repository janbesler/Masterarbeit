{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%store -r Kelmarsh_df Penmanshiel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataProcessor:\n",
    "    def __init__(self, dataframe, forecast, look_back, batch_size=64, train_size=0.7, test_size=0.5, random_state=42):\n",
    "        self.dataframe = dataframe\n",
    "        self.forecast = forecast\n",
    "        self.look_back = look_back\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def padding_data(self, dataframe):\n",
    "        remainder = dataframe.shape[0] % self.batch_size\n",
    "        if remainder == 0:\n",
    "            return dataframe # Already divisible by batch size\n",
    "        discard = remainder\n",
    "        if isinstance(dataframe, pd.DataFrame):\n",
    "            return dataframe[discard:]\n",
    "\n",
    "    def shifted_data(self):\n",
    "        data = self.dataframe\n",
    "        forecast = self.forecast\n",
    "        look_back = self.look_back\n",
    "        shifts = range(forecast, look_back + forecast)\n",
    "        variables = data.columns\n",
    "\n",
    "        shifted_columns = []\n",
    "        for column in variables:\n",
    "            for i in shifts:\n",
    "                shifted_df = data[[column]].shift(i)\n",
    "                shifted_df.rename(columns={column: f\"{column} (lag {i})\"}, inplace=True)\n",
    "                shifted_columns.append(shifted_df)\n",
    "        \n",
    "        data_shifted = pd.concat([data] + shifted_columns, axis=1)\n",
    "        data_shifted.dropna(inplace=True)\n",
    "\n",
    "        return data_shifted\n",
    "\n",
    "    def prepare_datasets(self):\n",
    "        try:\n",
    "            s_df = self.shifted_data().drop(['Wind speed (m/s)'], axis=1)\n",
    "        except KeyError:\n",
    "            s_df = self.shifted_data().copy()\n",
    "\n",
    "        # Splitting dataset\n",
    "        df_train, df_rem = train_test_split(s_df, train_size=self.train_size, random_state=self.random_state)\n",
    "        df_eval, df_test = train_test_split(df_rem, test_size=self.test_size, random_state=self.random_state)\n",
    "\n",
    "        df_train = self.padding_data(df_train)\n",
    "        df_eval = self.padding_data(df_eval)\n",
    "        df_test = self.padding_data(df_test)\n",
    "\n",
    "        # Wrapping datasets\n",
    "        self.train_dataset = TimeSeriesDataset(df_train)\n",
    "        self.test_dataset = TimeSeriesDataset(df_test)\n",
    "        self.eval_dataset = TimeSeriesDataset(df_eval)\n",
    "\n",
    "    def create_dataloaders(self):\n",
    "        self.prepare_datasets()\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        self.eval_loader = DataLoader(self.eval_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return self.train_loader, self.test_loader, self.eval_loader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.labels = dataframe.iloc[:, 0].values\n",
    "        self.features = dataframe.iloc[:, 1:].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Kelmarsh_df['1']\n",
    "data = data.set_index('# Date and time')\n",
    "data.index.names = [None]\n",
    "data = data.drop(['Long Term Wind (m/s)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TimeSeriesDataProcessor(dataframe=data, forecast=1, look_back=72, batch_size=64)\n",
    "train_loader, test_loader, eval_loader = processor.create_dataloaders()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
