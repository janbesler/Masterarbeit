{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%store -r Kelmarsh_df Penmanshiel_df test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Set\n",
    "\n",
    "2 approaches\n",
    "- naive n steps ahead forecast\n",
    "- recurrent shifting 1 step ahead forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recurrent forecast\n",
    "\n",
    "12 hours look back to predict next value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "look_back = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Kelmarsh_df['1'].set_index('# Date and time')\n",
    "df.index.names = [None]\n",
    "df = df.drop(['Long Term Wind (m/s)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shifting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_data(data: pd.DataFrame, forecast: int, look_back: int):\n",
    "    shifts = range(forecast, look_back + forecast)\n",
    "    variables = data.columns\n",
    "    \n",
    "    # List to store DataFrames for each shifted version\n",
    "    shifted_columns = []\n",
    "    \n",
    "    # Create shifted versions of each column\n",
    "    for column in variables:\n",
    "        for i in shifts:\n",
    "            shifted_df = data[[column]].shift(i)  # Shift and keep as DataFrame\n",
    "            shifted_df.rename(columns={column: f\"{column} (lag {i})\"}, inplace=True)\n",
    "            shifted_columns.append(shifted_df)\n",
    "    \n",
    "    # Concatenate all shifted columns with the original DataFrame at once\n",
    "    data_shifted = pd.concat([data] + shifted_columns, axis=1)\n",
    "    \n",
    "    # Drop rows with NaN values that were created due to shifting\n",
    "    data_shifted.dropna(inplace=True)\n",
    "    \n",
    "    return data_shifted\n",
    "\n",
    "s_df = shifted_data(data=df, forecast=1, look_back=72).drop(['Wind speed (m/s)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split into training and remaining dataset\n",
    "df_train, df_rem = train_test_split(s_df, train_size=0.7, random_state=42)\n",
    "\n",
    "# Split the remaining dataset into validation and test sets\n",
    "df_eval, df_test = train_test_split(df_rem, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        # Assuming the first column is the target variable\n",
    "        self.labels = dataframe.iloc[:, 0].values\n",
    "        self.features = dataframe.iloc[:, 1:].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data to PyTorch tensors\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return features, labels\n",
    "\n",
    "# Assuming df_train, df_test, df_eval are your datasets\n",
    "train_dataset = TimeSeriesDataset(df_train)\n",
    "test_dataset = TimeSeriesDataset(df_test)\n",
    "eval_dataset = TimeSeriesDataset(df_eval)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # Shuffle the data for training, typically not needed for test/eval\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataProcessor:\n",
    "    def __init__(self, dataframe, forecast, look_back, batch_size=64, train_size=0.7, test_size=0.5, random_state=42):\n",
    "        self.dataframe = dataframe\n",
    "        self.forecast = forecast\n",
    "        self.look_back = look_back\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def shifted_data(self):\n",
    "        data = self.dataframe\n",
    "        forecast = self.forecast\n",
    "        look_back = self.look_back\n",
    "        shifts = range(forecast, look_back + forecast)\n",
    "        variables = data.columns\n",
    "        \n",
    "        shifted_columns = []\n",
    "        for column in variables:\n",
    "            for i in shifts:\n",
    "                shifted_df = data[[column]].shift(i)\n",
    "                shifted_df.rename(columns={column: f\"{column} (lag {i})\"}, inplace=True)\n",
    "                shifted_columns.append(shifted_df)\n",
    "        \n",
    "        data_shifted = pd.concat([data] + shifted_columns, axis=1)\n",
    "        data_shifted.dropna(inplace=True)\n",
    "        \n",
    "        return data_shifted\n",
    "\n",
    "    def prepare_datasets(self):\n",
    "        s_df = self.shifted_data().drop(['Wind speed (m/s)'], axis=1)\n",
    "        \n",
    "        # Splitting dataset\n",
    "        df_train, df_rem = train_test_split(s_df, train_size=self.train_size, random_state=self.random_state)\n",
    "        df_eval, df_test = train_test_split(df_rem, test_size=self.test_size, random_state=self.random_state)\n",
    "\n",
    "        # Wrapping datasets\n",
    "        self.train_dataset = TimeSeriesDataset(df_train)\n",
    "        self.test_dataset = TimeSeriesDataset(df_test)\n",
    "        self.eval_dataset = TimeSeriesDataset(df_eval)\n",
    "\n",
    "    def create_dataloaders(self):\n",
    "        self.prepare_datasets()\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        self.eval_loader = DataLoader(self.eval_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return self.train_loader, self.test_loader, self.eval_loader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.labels = dataframe.iloc[:, 0].values\n",
    "        self.features = dataframe.iloc[:, 1:].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your initial DataFrame\n",
    "processor = TimeSeriesDataProcessor(dataframe=df, forecast=1, look_back=72, batch_size=64)\n",
    "train_loader, test_loader, eval_loader = processor.create_dataloaders()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
