{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "# reading data\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.fft import rfft, irfft, fftn, ifftn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# eFormer\n",
    "from eFormer.embeddings import Encoding, ProbEncoding, PositionalEncoding\n",
    "from eFormer.sparse_attention import ProbSparseAttentionModule, DetSparseAttentionModule\n",
    "from eFormer.loss_function import crps\n",
    "from eFormer.sparse_decoder import DetSparseDecoder, ProbSparseDecoder\n",
    "from eFormer.Dataloader import TimeSeriesDataProcessor\n",
    "\n",
    "%store -r Kelmarsh_df Penmanshiel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global parameters\n",
    "\n",
    "n_heads_global = 4\n",
    "probabilistic_model = False\n",
    "len_embedding_vector = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_data(data, forecast, look_back):\n",
    "    data = data.set_index('# Date and time')\n",
    "    data.index.names = [None]\n",
    "    data = data.drop(['Long Term Wind (m/s)'], axis=1)\n",
    "    shifts = range(forecast, look_back + forecast)\n",
    "    variables = data.columns\n",
    "        \n",
    "    shifted_columns = []\n",
    "    for column in variables:\n",
    "        for i in shifts:\n",
    "            shifted_df = data[[column]].shift(i)\n",
    "            shifted_df.rename(columns={column: f\"{column} (lag {i})\"}, inplace=True)\n",
    "            shifted_columns.append(shifted_df)\n",
    "        \n",
    "    data = data.drop(['Wind speed (m/s)'], axis=1)\n",
    "    data_shifted = pd.concat([data] + shifted_columns, axis=1)\n",
    "    data_shifted.dropna(inplace=True)\n",
    "        \n",
    "    return data_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'shifted_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "shifted_df = shifted_data(\n",
    "    Kelmarsh_df['1'][-4096:],\n",
    "    forecast=1,\n",
    "    look_back=72\n",
    "    )\n",
    "\n",
    "%store shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Kelmarsh_df['1'][-4096:]\n",
    "data = data.set_index('# Date and time')\n",
    "data.index.names = [None]\n",
    "data = data.drop(['Long Term Wind (m/s)'], axis=1)\n",
    "\n",
    "test_df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your initial DataFrame\n",
    "processor = TimeSeriesDataProcessor(\n",
    "    dataframe=test_df,\n",
    "    forecast=1,\n",
    "    look_back=72,\n",
    "    batch_size=64)\n",
    "    \n",
    "train_loader, test_loader, eval_loader = processor.create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eFormer(nn.Module):\n",
    "    def __init__(self, in_features, len_embedding_vector, n_heads_global, probabilistic_model=False):\n",
    "        super(eFormer, self).__init__()\n",
    "        self.probabilistic_model = probabilistic_model\n",
    "        self.n_heads_global = n_heads_global\n",
    "        self.len_embedding_vector = len_embedding_vector\n",
    "\n",
    "        # Initialize encoding model\n",
    "        if probabilistic_model:\n",
    "            self.encoding_model = ProbEncoding(in_features=in_features, out_features=len_embedding_vector)\n",
    "        else:\n",
    "            self.encoding_model = Encoding(in_features=in_features, out_features=len_embedding_vector)\n",
    "\n",
    "        # Initialize attention module\n",
    "        if probabilistic_model:\n",
    "            self.attention_module = ProbSparseAttentionModule(d_model=len_embedding_vector, n_heads=n_heads_global, prob_sparse_factor=5)\n",
    "        else:\n",
    "            self.attention_module = DetSparseAttentionModule(d_model=len_embedding_vector, n_heads=n_heads_global, prob_sparse_factor=5)\n",
    "\n",
    "        # Initialize decoder\n",
    "        # Assuming the decoder initialization does not actually require the output shape directly but parameters that depend on the model configuration\n",
    "        if probabilistic_model:\n",
    "            self.decoder = ProbSparseDecoder(d_model=len_embedding_vector, n_heads=n_heads_global, forecast_horizon=1, encoder_output_dim=len_embedding_vector)\n",
    "        else:\n",
    "            self.decoder = DetSparseDecoder(d_model=len_embedding_vector, n_heads=n_heads_global, forecast_horizon=1, encoder_output_dim=len_embedding_vector)\n",
    "\n",
    "    def forward(self, features_matrix):\n",
    "        if torch.isnan(features_matrix).any():\n",
    "            raise ValueError('NaN values detected in Input')\n",
    "\n",
    "        embeddings = self.encoding_model(features_matrix)\n",
    "        if torch.isnan(embeddings).any():\n",
    "            raise ValueError('NaN values detected in Embeddings')\n",
    "\n",
    "        encoder_output = self.attention_module(embeddings, embeddings, embeddings)\n",
    "        if torch.isnan(encoder_output).any():\n",
    "            raise ValueError('NaN values detected in Sparse Attention Output')\n",
    "\n",
    "        forecasts, crps_weights = self.decoder(encoder_output)\n",
    "        return forecasts, crps_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels & features: (torch.Size([64]), torch.Size([64, 144]))\n",
      "Stored 'features' (Tensor)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    features, labels = batch\n",
    "    break\n",
    "\n",
    "print(f\"labels & features: {labels.shape, features.shape}\")\n",
    "\n",
    "%store features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions type: torch.Size([1, 64]) \n",
      " crsp_weights type: torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.var/app/com.vscodium.codium/data/python/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cumsum() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=int, ), but expected one of:\n * (int dim, *, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, *, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m predictions, crps_weights \u001b[39m=\u001b[39m model(features)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredictions type: \u001b[39m\u001b[39m{\u001b[39;00mpredictions\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m crsp_weights type: \u001b[39m\u001b[39m{\u001b[39;00mcrps_weights\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(forecast\u001b[39m=\u001b[39;49mpredictions, observations\u001b[39m=\u001b[39;49mlabels, weights\u001b[39m=\u001b[39;49mcrps_weights)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jan/Documents/Masterarbeit/src/2_0_eFormer.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/src/eFormer/loss_function.py:29\u001b[0m, in \u001b[0;36mcrps\u001b[0;34m(forecast, observations, weights)\u001b[0m\n\u001b[1;32m     26\u001b[0m observations \u001b[39m=\u001b[39m observations[np\u001b[39m.\u001b[39mnewaxis, :]\n\u001b[1;32m     28\u001b[0m \u001b[39m# Calculate CRPS\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m cumsum_forecast \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcumsum(forecast, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m/\u001b[39m forecast\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m crps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((cumsum_forecast \u001b[39m-\u001b[39m (forecast \u001b[39m>\u001b[39m observations)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# weighted median of CRPS\u001b[39;00m\n",
      "File \u001b[0;32m~/.var/app/com.vscodium.codium/data/python/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2586\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2512\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcumsum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2514\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2515\u001b[0m \u001b[39m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2516\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2584\u001b[0m \n\u001b[1;32m   2585\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2586\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mcumsum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[0;32m~/.var/app/com.vscodium.codium/data/python/lib/python3.11/site-packages/numpy/core/fromnumeric.py:68\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.var/app/com.vscodium.codium/data/python/lib/python3.11/site-packages/numpy/core/fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/.var/app/com.vscodium.codium/data/python/lib/python3.11/site-packages/torch/_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m   1031\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "model = eFormer(\n",
    "    in_features=(features.shape[-1]),\n",
    "    len_embedding_vector=64,\n",
    "    n_heads_global=4,\n",
    "    probabilistic_model=False)\n",
    "optimizer = AdamW(\n",
    "    params = model.parameters(),\n",
    "    lr=6e-4,\n",
    "    weight_decay=1e-1\n",
    "    )\n",
    "loss_fn = crps\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions, crps_weights = model(features)\n",
    "        print(f\"predictions type: {predictions.shape} \\n crsp_weights type: {crps_weights.shape}\")\n",
    "        loss = loss_fn(forecast=predictions, observations=labels, weights=crps_weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch} / {num_epochs} with Loss: {loss}\")\n",
    "\n",
    "    # Evaluate your model's performance on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            predictions = model(features)\n",
    "            # Calculate and print validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3878, 145)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            self.val_loss_min = val_loss\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    train_loss_avg = np.mean(train_losses)\n",
    "    print(f\"Epoch {epoch} / {num_epochs} with Loss: {train_loss_avg}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    validation_losses = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in eval_loader:\n",
    "            predictions = model(features)\n",
    "            val_loss = loss_fn(predictions, labels)\n",
    "            validation_losses.append(val_loss.item())\n",
    "\n",
    "    val_loss_avg = np.mean(validation_losses)\n",
    "    print(f\"Validation Loss: {val_loss_avg}\")\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch Duration: {epoch_duration}s\")\n",
    "\n",
    "    early_stopping(val_loss_avg)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_system_conditions():\n",
    "    # Get CPU usage for each core\n",
    "    cpu_percent = round(psutil.cpu_percent(), 4)\n",
    "\n",
    "    # Get memory information\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    memory_used_gb = round(memory_info.used / (1024 ** 3), 4)\n",
    "\n",
    "    # Get GPU information\n",
    "    try:\n",
    "      gpu_info = GPUtil.getGPUs()[0]\n",
    "      gpu_memory_used_gb = round(gpu_info.memoryUsed / 1024, 4)\n",
    "    except IndexError:\n",
    "      # If no GPU is found, set variables to None\n",
    "      gpu_memory_used_gb = None\n",
    "\n",
    "    # Collect data in a dictionary\n",
    "    comp_usage = {\n",
    "        'CPU Usage': cpu_percent,\n",
    "        'Memory Usage (GB)': memory_used_gb,\n",
    "        'GPU Usage (GB)': gpu_memory_used_gb\n",
    "    }\n",
    "\n",
    "    return comp_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "# Assuming the check_system_conditions function is defined as previously mentioned\n",
    "\n",
    "# Define a function to run monitoring in a separate thread\n",
    "def monitor_system_usage(every_n_seconds=10, keep_running=lambda: True, results_list=[]):\n",
    "    while keep_running():\n",
    "        comp_usage = check_system_conditions()\n",
    "        results_list.append(comp_usage)\n",
    "        time.sleep(every_n_seconds)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "system_usage_results = []\n",
    "\n",
    "# Define a lambda function to control the monitoring loop\n",
    "# It will return False to stop the thread once training is done\n",
    "keep_monitoring = lambda: keep_monitoring_flag\n",
    "\n",
    "# Initialize the flag to True before starting training\n",
    "keep_monitoring_flag = True\n",
    "\n",
    "# Start the monitoring thread\n",
    "monitor_thread = threading.Thread(target=monitor_system_usage, args=(5, keep_monitoring, system_usage_results))\n",
    "monitor_thread.start()\n",
    "\n",
    "# Training loop here\n",
    "# Insert your existing training loop code\n",
    "\n",
    "# After training is done, set the flag to False to stop the monitoring thread\n",
    "keep_monitoring_flag = False\n",
    "monitor_thread.join()  # Wait for the monitoring thread to finish\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "system_usage_df = pd.DataFrame(system_usage_results)\n",
    "\n",
    "print(system_usage_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
